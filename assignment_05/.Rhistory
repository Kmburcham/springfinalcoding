library(readr)
CarSales <- read_csv("GitHub/mybrainfuzzies/CarSales.csv")
View(CarSales)
View(CarSales)
View(CarSales)
View(CarSales)
q()
load("C:/Users/Kaylei Burcham/Desktop/springfinalcoding/springfinalcoding/assignment_05/applications_full.csv")
setwd("C:/Users/Kaylei Burcham/Desktop/springfinalcoding/springfinalcoding/assignment_05")
rm(list=ls(all=TRUE))
# Load necessary libraries
library(tidyverse)
library(tidymodels)
library(randomForest)
library(xgboost)
# Load data
applications <- read.csv('applications_full.csv')
credit_bureau <- read.csv('credit_bureau_full.csv')
demographic <- read.csv('demographic_full.csv')
# Merge datasets
purchases_full <- merge(applications, credit_bureau, by = c('ssn', 'year'))
purchases_full <- merge(purchases_full, demographic, by.x = c('zip_code.x', 'year'), by.y = c('zip_code', 'year'))
# Create new variables
purchases_full$utilization <- purchases_full$purchases / purchases_full$credit_limit
purchases_full$log_odds_util <- log(purchases_full$utilization / (1 - purchases_full$utilization))
# Split training data (2022 only)
purchases_2022 <- purchases_full[purchases_full$year == 2022, ]
# Define recipes
model_recipe_purch <- recipe(purchases ~ fico + income + homeownership + num_late + past_def + num_bankruptcy + avg_income + density, data = purchases_2022) %>% step_dummy(homeownership)
model_recipe_util <- recipe(utilization ~ fico + income + homeownership + num_late + past_def + num_bankruptcy + avg_income + density, data = purchases_2022) %>% step_dummy(homeownership)
# Model specs
model_lm <- linear_reg() %>% set_mode("regression") %>% set_engine("lm")
model_dt <- decision_tree(mode = "regression", engine = "rpart", cost_complexity = 0.01, tree_depth = 4, min_n = 10)
model_rf <- rand_forest(mtry = 6, trees = 200, min_n = 4) %>% set_mode("regression") %>% set_engine("randomForest")
model_xgb <- boost_tree(trees = 150, min_n = 3, tree_depth = 5, learn_rate = 0.05, loss_reduction = 0.05, sample_size = 0.7) %>% set_mode("regression") %>% set_engine("xgboost")
# Workflows
model_wflow_lm_purch <- workflow() %>% add_model(model_lm) %>% add_recipe(model_recipe_purch)
model_wflow_lm_util <- workflow() %>% add_model(model_lm) %>% add_recipe(model_recipe_util)
model_wflow_dt <- workflow() %>% add_model(model_dt) %>% add_recipe(model_recipe_purch)
model_wflow_rf <- workflow() %>% add_model(model_rf) %>% add_recipe(model_recipe_purch)
model_wflow_xgb <- workflow() %>% add_model(model_xgb) %>% add_recipe(model_recipe_purch)
# Fit models (on 2022 data only)
model_fit_lm_purch <- model_wflow_lm_purch %>% fit(data = purchases_2022)
model_fit_lm_util <- model_wflow_lm_util %>% fit(data = purchases_2022)
model_fit_dt <- model_wflow_dt %>% fit(data = purchases_2022)
model_fit_rf <- model_wflow_rf %>% fit(data = purchases_2022)
model_fit_xgb <- model_wflow_xgb %>% fit(data = purchases_2022)
# Function to evaluate models
evaluate_models <- function(df) {
df$pred_lm_purch <- predict(model_fit_lm_purch, df)$.pred
df$error_lm_purch <- df$pred_lm_purch - df$purchases
util_pred <- predict(model_fit_lm_util, df)$.pred
df$pred_lm_util <- util_pred * df$credit_limit
df$error_lm_util <- df$pred_lm_util - df$purchases
df$pred_dt <- predict(model_fit_dt, df)$.pred
df$error_dt <- df$pred_dt - df$purchases
df$pred_rf <- predict(model_fit_rf, df)$.pred
df$error_rf <- df$pred_rf - df$purchases
df$pred_xgb <- predict(model_fit_xgb, df)$.pred
df$error_xgb <- df$pred_xgb - df$purchases
return(df)
}
# Evaluate on each year and print MAEs
for (yr in c(2022, 2023, 2024))
df <- purchases_full[purchases_full$year == yr, ]
df <- evaluate_models(df)
mae_result <- tibble(
Year = yr,
MAE_LM_Purch = mean(abs(df$error_lm_purch), na.rm = TRUE),
MAE_LM_Util = mean(abs(df$error_lm_util), na.rm = TRUE),
MAE_DT = mean(abs(df$error_dt), na.rm = TRUE),
MAE_RF = mean(abs(df$error_rf), na.rm = TRUE),
MAE_XGB = mean(abs(df$error_xgb), na.rm = TRUE)
)
print(mae_result)
##################################################
# End
##################################################
rm(list=ls(all=TRUE))
# Load necessary libraries
library(tidyverse)
library(tidymodels)
library(randomForest)
library(xgboost)
# Load data
applications <- read.csv('applications_full.csv')
credit_bureau <- read.csv('credit_bureau_full.csv')
demographic <- read.csv('demographic_full.csv')
# Merge datasets
purchases_full <- merge(applications, credit_bureau, by = c('ssn', 'year'))
purchases_full <- merge(purchases_full, demographic, by.x = c('zip_code.x', 'year'), by.y = c('zip_code', 'year'))
# Create new variables
purchases_full$utilization <- purchases_full$purchases / purchases_full$credit_limit
purchases_full$log_odds_util <- log(purchases_full$utilization / (1 - purchases_full$utilization))
# Split training data (2022 only)
purchases_2022 <- purchases_full[purchases_full$year == 2022, ]
# Define recipes
model_recipe_purch <- recipe(purchases ~ fico + income + homeownership + num_late + past_def + num_bankruptcy + avg_income + density, data = purchases_2022) %>% step_dummy(homeownership)
model_recipe_util <- recipe(utilization ~ fico + income + homeownership + num_late + past_def + num_bankruptcy + avg_income + density, data = purchases_2022) %>% step_dummy(homeownership)
# Model specs
model_lm <- linear_reg() %>% set_mode("regression") %>% set_engine("lm")
model_dt <- decision_tree(mode = "regression", engine = "rpart", cost_complexity = 0.01, tree_depth = 4, min_n = 10)
model_rf <- rand_forest(mtry = 6, trees = 200, min_n = 4) %>% set_mode("regression") %>% set_engine("randomForest")
model_xgb <- boost_tree(trees = 150, min_n = 3, tree_depth = 5, learn_rate = 0.05, loss_reduction = 0.05, sample_size = 0.7) %>% set_mode("regression") %>% set_engine("xgboost")
# Workflows
model_wflow_lm_purch <- workflow() %>% add_model(model_lm) %>% add_recipe(model_recipe_purch)
model_wflow_lm_util <- workflow() %>% add_model(model_lm) %>% add_recipe(model_recipe_util)
model_wflow_dt <- workflow() %>% add_model(model_dt) %>% add_recipe(model_recipe_purch)
model_wflow_rf <- workflow() %>% add_model(model_rf) %>% add_recipe(model_recipe_purch)
model_wflow_xgb <- workflow() %>% add_model(model_xgb) %>% add_recipe(model_recipe_purch)
# Fit models (on 2022 data only)
model_fit_lm_purch <- model_wflow_lm_purch %>% fit(data = purchases_2022)
model_fit_lm_util <- model_wflow_lm_util %>% fit(data = purchases_2022)
model_fit_dt <- model_wflow_dt %>% fit(data = purchases_2022)
model_fit_rf <- model_wflow_rf %>% fit(data = purchases_2022)
model_fit_xgb <- model_wflow_xgb %>% fit(data = purchases_2022)
# Function to evaluate models
evaluate_models <- function(df) {
df$pred_lm_purch <- predict(model_fit_lm_purch, df)$.pred
df$error_lm_purch <- df$pred_lm_purch - df$purchases
util_pred <- predict(model_fit_lm_util, df)$.pred
df$pred_lm_util <- util_pred * df$credit_limit
df$error_lm_util <- df$pred_lm_util - df$purchases
df$pred_dt <- predict(model_fit_dt, df)$.pred
df$error_dt <- df$pred_dt - df$purchases
df$pred_rf <- predict(model_fit_rf, df)$.pred
df$error_rf <- df$pred_rf - df$purchases
df$pred_xgb <- predict(model_fit_xgb, df)$.pred
df$error_xgb <- df$pred_xgb - df$purchases
return(df)
}
# Evaluate on each year and print MAEs
for (yr in c(2022, 2023, 2024)) {
df <- purchases_full[purchases_full$year == yr, ]
df <- evaluate_models(df)
mae_result <- tibble(
Year = yr,
MAE_LM_Purch = mean(abs(df$error_lm_purch), na.rm = TRUE),
MAE_LM_Util = mean(abs(df$error_lm_util), na.rm = TRUE),
MAE_DT = mean(abs(df$error_dt), na.rm = TRUE),
MAE_RF = mean(abs(df$error_rf), na.rm = TRUE),
MAE_XGB = mean(abs(df$error_xgb), na.rm = TRUE)
)
print(mae_result)
}
##################################################
# End
##################################################
